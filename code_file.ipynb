{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R80ygpJmIBgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6bd333-c12d-49f7-c2f2-0b2ffd57e5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 31 18:42:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O6Sju1QKTQ_",
        "outputId": "d64c0c59-e7f5-4443-da46-5716677f9f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WYjs2r618Uo7"
      },
      "outputs": [],
      "source": [
        "!unzip -q '/content/gdrive/ My Drive/cats_and_dogs_small-hw.zip' \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary packages"
      ],
      "metadata": {
        "id": "jKIXEV2vDoBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import tensorflow as tf\n",
        "from itertools import cycle\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import auc, roc_auc_score,classification_report,roc_curve\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten, Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "AUdNXlKmDlhV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16 Architecture"
      ],
      "metadata": {
        "id": "bOFkQrz1BO2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q95Urj63SAHz"
      },
      "outputs": [],
      "source": [
        "class VGG16:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # initialize the model\n",
        "        model = Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "        # if we are using \"channels first\", update the input shape\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "        # first set of CONV => RELU => POOL layers\n",
        "        #block1\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=inputShape))\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\",activation='relu', input_shape=inputShape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        # second set of CONV => RELU => POOL layers\n",
        "        #block2\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu', input_shape=inputShape))\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\",activation='relu', input_shape=inputShape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        #block3\n",
        "        model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu', input_shape=inputShape))\n",
        "        model.add(Conv2D(256, (3, 3), padding=\"same\",activation='relu', input_shape=inputShape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        #block4\n",
        "        model.add(Conv2D(512, (3, 3), padding=\"same\", activation='relu', input_shape=inputShape))\n",
        "        model.add(Conv2D(512, (3, 3), padding=\"same\",activation='relu', input_shape=inputShape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        #block5\n",
        "        model.add(Conv2D(512, (3, 3), padding=\"same\", activation='relu', input_shape=inputShape))\n",
        "        model.add(Conv2D(512, (3, 3), padding=\"same\",activation='relu', input_shape=inputShape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        # first (and only) set of FC => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        # softmax classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "        # return the constructed network architecture\n",
        "        return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mixup Augmentation"
      ],
      "metadata": {
        "id": "jYRcRk0lBc37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o2P_ujLvzX6P"
      },
      "outputs": [],
      "source": [
        "# For Beta distribution.\n",
        "alpha = [0.2]\n",
        "beta = [0.2]\n",
        "def mixup(a, b):\n",
        "  \n",
        "  (image1, label1), (image2, label2) = a, b\n",
        "\n",
        "  dist = tfd.Beta(alpha, beta)\n",
        "  l = dist.sample(1)[0][0]\n",
        "  \n",
        "  img = l*image1+(1-l)*image2\n",
        "  lab = l*label1+(1-l)*label2\n",
        "\n",
        "  return img, lab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cutmix Augmentation"
      ],
      "metadata": {
        "id": "J-qPF4xMBmLk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FfDamcUmPQap"
      },
      "outputs": [],
      "source": [
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "import tensorflow as tf\n",
        "IMG_SHAPE = 128\n",
        "def get_bbox(l):\n",
        "  cut_rat = tf.math.sqrt(1.-l)\n",
        "\n",
        "  cut_w = IMG_SHAPE*cut_rat #rw\n",
        "  cut_w = tf.cast(cut_w, tf.int32)\n",
        "  \n",
        "  cut_h = IMG_SHAPE*cut_rat #rh\n",
        "  cut_h = tf.cast(cut_h, tf.int32)\n",
        "  \n",
        "  cx = tf.random.uniform((1,), minval=0, maxval=IMG_SHAPE, dtype=tf.int32) #rx\n",
        "  cy = tf.random.uniform((1,), minval=0, maxval=IMG_SHAPE, dtype=tf.int32) #ry\n",
        "  \n",
        "  bbx1 = tf.clip_by_value(cx[0] - cut_w // 2, 0, IMG_SHAPE)\n",
        "  bby1 = tf.clip_by_value(cy[0] - cut_h // 2, 0, IMG_SHAPE)\n",
        "  bbx2 = tf.clip_by_value(cx[0] + cut_w // 2, 0, IMG_SHAPE)\n",
        "  bby2 = tf.clip_by_value(cy[0] + cut_h // 2, 0, IMG_SHAPE)\n",
        "  \n",
        "  target_h = bby2-bby1\n",
        "  if target_h ==0:\n",
        "    target_h+=1\n",
        "\n",
        "  target_w = bbx2-bbx1\n",
        "  if target_w ==0:\n",
        "    target_w+=1\n",
        "\n",
        "  return bbx1, bby1, target_h, target_w\n",
        "\n",
        "@tf.function\n",
        "def cutmix(a, b):\n",
        "  \n",
        "  (image1, label1), (image2, label2) = a, b\n",
        "\n",
        "  alpha = [1.]\n",
        "  beta = [1.]\n",
        "  \n",
        "  ## Get sample from beta distribution\n",
        "  dist = tfd.Beta(alpha, beta)\n",
        "  ## Lambda\n",
        "  l = dist.sample(1)[0][0]\n",
        "\n",
        "  ## Get bbox ofsets and heights and widths\n",
        "  bbx1, bby1, target_h, target_w = get_bbox(l)\n",
        "\n",
        "  ## Get patch from image2\n",
        "  crop2 = tf.image.crop_to_bounding_box(image2, bby1, bbx1, target_h, target_w)\n",
        "  ## Pad the patch with same offset\n",
        "  image2 = tf.image.pad_to_bounding_box(crop2, bby1, bbx1, IMG_SHAPE, IMG_SHAPE)\n",
        "  ## Get patch from image1\n",
        "  crop1 = tf.image.crop_to_bounding_box(image1, bby1, bbx1, target_h, target_w)\n",
        "  ## Pad the patch with same offset\n",
        "  img1 = tf.image.pad_to_bounding_box(crop1, bby1, bbx1, IMG_SHAPE, IMG_SHAPE)\n",
        "\n",
        "  ## Subtract the patch from image1 so that patch from image2 can be put on instead\n",
        "  image1 = image1-img1\n",
        "  ## Add modified image1 and image2 to get cutmix image\n",
        "  image = image1+image2\n",
        "\n",
        "  ## Adjust lambda according to pixel ration\n",
        "  l = 1 - (target_w * target_h) / (IMG_SHAPE * IMG_SHAPE)\n",
        "  l = tf.cast(l, tf.float32)\n",
        "\n",
        "  ## Combine labels\n",
        "  label = l*label1+(1-l)*label2\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train, val, and test set\n",
        "Preprocess image"
      ],
      "metadata": {
        "id": "5iRECJ9JCzbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotpath= \"/content/plot1.png\"\n",
        "datatrain= \"/content/cats_and_dogs_small/train\"\n",
        "dataval=\"/content/cats_and_dogs_small/validation\"\n",
        "datatest=\"/content/cats_and_dogs_small/test\"\n",
        "# initialize the number of epochs to train for, initia learning rate,\n",
        "# and batch size\n",
        "EPOCHS = 300\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "# initialize the data and labels\n",
        "print(\"[INFO] loading images...\")\n",
        "traindata = []\n",
        "trainlabels = []\n",
        "valdata = []\n",
        "vallabels = []\n",
        "testdata = []\n",
        "testlabels = []\n",
        "# grab the image paths and randomly shuffle them\n",
        "trainPaths = list(paths.list_images(datatrain))\n",
        "\n",
        "for trainPath in trainPaths:\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    trainimage = cv2.imread(trainPath)\n",
        "    trainimage = cv2.resize(trainimage, (128, 128))\n",
        "    #cv2_imshow(trainimage)\n",
        "    #cv2.waitKey(0)\n",
        "\n",
        "    trainimage = img_to_array(trainimage)\n",
        "    traindata.append(trainimage)\n",
        "    # extract the class label from the image path and update the\n",
        "    # labels list\n",
        "    trainlabel = trainPath.split(os.path.sep)[-2]\n",
        "    trainlabel = 1 if trainlabel == \"dogs\" else 0\n",
        "    trainlabels.append(trainlabel)\n",
        " # scale the raw pixel intensities to the range [0, 1]\n",
        "trainX = np.array(traindata, dtype=\"float32\") / 255.0\n",
        "trainY = np.array(trainlabels)\n",
        "#val\n",
        "valPaths = list(paths.list_images(dataval))\n",
        "\n",
        "testPaths = list(paths.list_images(datatest))\n",
        "\n",
        "for testPath in testPaths:\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    testimage = cv2.imread(testPath)\n",
        "    testimage = cv2.resize(testimage, (128, 128))\n",
        "    testimage = img_to_array(testimage)\n",
        "    testdata.append(testimage)\n",
        "    # extract the class label from the image path and update the\n",
        "    # labels list\n",
        "    testlabel = testPath.split(os.path.sep)[-2]\n",
        "    testlabel = 1 if testlabel == \"dogs\" else 0\n",
        "    testlabels.append(testlabel)\n",
        " # scale the raw pixel intensities to the range [0, 1]\n",
        "testX = np.array(testdata, dtype=\"float32\") / 255.0\n",
        "testY = np.array(testlabels)\n",
        "for valPath in valPaths:\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    valimage = cv2.imread(valPath)\n",
        "    valimage = cv2.resize(valimage, (128, 128))\n",
        "    valimage = img_to_array(valimage)\n",
        "    valdata.append(valimage)\n",
        "    # extract the class label from the image path and update the\n",
        "    # labels list\n",
        "    vallabel = valPath.split(os.path.sep)[-2]\n",
        "    vallabel = 1 if vallabel == \"dogs\" else 0\n",
        "    vallabels.append(vallabel)\n",
        " # scale the raw pixel intensities to the range [0, 1]\n",
        "valX = np.array(valdata, dtype=\"float32\") / 255.0\n",
        "valY = np.array(vallabels)\n",
        "# convert the labels from integers to vectors\n",
        "trainY = to_categorical(trainY, num_classes=2)\n",
        "valY = to_categorical(valY, num_classes=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFnwteJ3Cycc",
        "outputId": "d91b622c-4600-4fac-fef1-7c6092b6e778"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with Cutmix Augmentation"
      ],
      "metadata": {
        "id": "AlswfJ-_Cfks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g6ojywrTa6T"
      },
      "outputs": [],
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "trainloader1 = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(4096)\n",
        "trainloader2 = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(4096)\n",
        "\n",
        "trainloader = tf.data.Dataset.zip((trainloader1, trainloader2))\n",
        "trainloader = (trainloader.shuffle(4096).map(cutmix, num_parallel_calls=AUTO).batch(32).prefetch(AUTO))\n",
        "\n",
        "valloader = tf.data.Dataset.from_tensor_slices((valX, valY))\n",
        "valloader = (valloader.batch(32).prefetch(AUTO))\n",
        "     \n",
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = VGG16.build(width=128, height=128, depth=3, classes=2)\n",
        "opt=SGD(learning_rate=INIT_LR, momentum=0.9)\n",
        "model.compile(loss=losses.BinaryCrossentropy(label_smoothing=0.1), optimizer=opt, metrics=[\"accuracy\"])\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(x=trainloader,validation_data=valloader, epochs=EPOCHS)\n",
        "# prediction\n",
        "predictions = model.predict(testX)\n",
        "predictions=predictions.argmax(axis=-1)\n",
        "class_labels = ['cats', 'dogs']\n",
        "y_score = model.predict(testX, batch_size = 32) # one hot encoded softmax predictions\n",
        "ytest_binary = label_binarize(testY, classes = [0,1,2]) # one hot encode the test data true labels\n",
        "n_classes=2\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict() \n",
        "# compute fpr and tpr with roc_curve from the ytest true labels to the scores\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(ytest_binary[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# plot each class  curve on single graph for multi-class one vs all classification\n",
        "colors = cycle(['blue', 'red', 'green'])\n",
        "for i, color, lbl in zip(range(n_classes), colors, class_labels):\n",
        "    plt.plot(fpr[i], tpr[i], color = color, lw = 1.5,\n",
        "    label = 'ROC Curve of class {0} (area = {1:0.3f})'.format(lbl, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1.5)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for cats and dogs Data')\n",
        "plt.legend(loc = 'lower right', prop = {'size': 6})\n",
        "fullpath = '/content/roc_curve.png'\n",
        "plt.savefig(fullpath)\n",
        "plt.show()\n",
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(\"/content/cats_and_dogs.h5\", save_format=\"h5\")\n",
        "print(classification_report(testY, predictions))\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dogs/Cats\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(plotpath)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with mixup augmentation"
      ],
      "metadata": {
        "id": "1pxiHdZpGWaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "trainloader1 = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(4096)\n",
        "trainloader2 = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(4096)\n",
        "\n",
        "trainloader = tf.data.Dataset.zip((trainloader1, trainloader2))\n",
        "trainloader = (trainloader.shuffle(4096).map(mixup, num_parallel_calls=AUTO).batch(32).prefetch(AUTO))\n",
        "\n",
        "valloader = tf.data.Dataset.from_tensor_slices((valX, valY))\n",
        "valloader = (valloader.batch(32).prefetch(AUTO))\n",
        "     \n",
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = VGG16.build(width=128, height=128, depth=3, classes=2)\n",
        "opt=SGD(learning_rate=INIT_LR, momentum=0.9)\n",
        "model.compile(loss=losses.BinaryCrossentropy(label_smoothing=0.1), optimizer=opt, metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(x=trainloader,validation_data=valloader, epochs=EPOCHS)\n",
        "# prediction\n",
        "predictions = model.predict(testX)\n",
        "predictions=predictions.argmax(axis=-1)\n",
        "class_labels = ['cats', 'dogs']\n",
        "y_score = model.predict(testX, batch_size = 32) # one hot encoded softmax predictions\n",
        "ytest_binary = label_binarize(testY, classes = [0,1,2]) # one hot encode the test data true labels\n",
        "n_classes=2\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict() \n",
        "# compute fpr and tpr with roc_curve from the ytest true labels to the scores\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(ytest_binary[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# plot each class  curve on single graph for multi-class one vs all classification\n",
        "colors = cycle(['blue', 'red', 'green'])\n",
        "for i, color, lbl in zip(range(n_classes), colors, class_labels):\n",
        "    plt.plot(fpr[i], tpr[i], color = color, lw = 1.5,\n",
        "    label = 'ROC Curve of class {0} (area = {1:0.3f})'.format(lbl, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1.5)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for cats and dogs Data')\n",
        "plt.legend(loc = 'lower right', prop = {'size': 6})\n",
        "fullpath = '/content/roc_curve.png'\n",
        "plt.savefig(fullpath)\n",
        "plt.show()\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(\"/content/cats_and_dogs.h5\", save_format=\"h5\")\n",
        "print(classification_report(testY, predictions))\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dogs/Cats\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(plotpath)"
      ],
      "metadata": {
        "id": "FLsHViAEYpxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with not augmented"
      ],
      "metadata": {
        "id": "w7FbU_gTFj-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = VGG16.build(width=128, height=128, depth=3, classes=2)\n",
        "opt=SGD(learning_rate=INIT_LR, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(x=trainX, y=trainY,validation_data=(valX, valY), steps_per_epoch=len(trainX) // BS,epochs=EPOCHS, verbose=1)\n",
        "# prediction\n",
        "predictions = model.predict(testX)\n",
        "predictions=predictions.argmax(axis=-1)\n",
        "class_labels = ['cats', 'dogs']\n",
        "y_score = model.predict(testX, batch_size = 32) # one hot encoded softmax predictions\n",
        "ytest_binary = label_binarize(testY, classes = [0,1,2]) # one hot encode the test data true labels\n",
        "n_classes=2\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict() \n",
        "# compute fpr and tpr with roc_curve from the ytest true labels to the scores\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(ytest_binary[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# plot each class  curve on single graph for multi-class one vs all classification\n",
        "colors = cycle(['blue', 'red', 'green'])\n",
        "for i, color, lbl in zip(range(n_classes), colors, class_labels):\n",
        "    plt.plot(fpr[i], tpr[i], color = color, lw = 1.5,\n",
        "    label = 'ROC Curve of class {0} (area = {1:0.3f})'.format(lbl, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw = 1.5)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for cats and dogs Data')\n",
        "plt.legend(loc = 'lower right', prop = {'size': 6})\n",
        "fullpath = '/content/roc_curve.png'\n",
        "plt.savefig(fullpath)\n",
        "plt.show()\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(\"/content/cats_and_dogs.h5\", save_format=\"h5\")\n",
        "print(classification_report(testY, predictions))\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dogs/Cats\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(plotpath)"
      ],
      "metadata": {
        "id": "h2J4vTDrdPzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate and test model"
      ],
      "metadata": {
        "id": "hVOkpISCGbdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nktE3nLNKN4W"
      },
      "outputs": [],
      "source": [
        "#Evaluating our Convolutional Neural Network image classifier\n",
        "# grab the image paths and randomly shuffle them\n",
        "#trainPaths = sorted(list(paths.list_images(datatest)))\n",
        "#random.seed(42)\n",
        "#random.shuffle(trainPaths)\n",
        "#for trainPath in trainPaths:\n",
        "# load the image, pre-process it, and store it in the data list\n",
        "trainPath= '/content/111.jpg'\n",
        "trainimage = cv2.imread(trainPath)\n",
        "trainimage = cv2.imread(trainPath)\n",
        "orig=trainimage.copy()\n",
        "\n",
        "trainimage = cv2.resize(trainimage, (128, 128))\n",
        "trainimage = img_to_array(trainimage)\n",
        "\n",
        "image = np.expand_dims(trainimage, axis=0)\n",
        "# load the trained convolutional neural network\n",
        "print(\"[INFO] loading network...\")\n",
        "model = load_model(\"/content/cats_and_dogs.h5\")\n",
        "# classify the input image\n",
        "(cats, dogs) = model.predict(image)[0]\n",
        "# build the label\n",
        "label = \"dogs\" if dogs > cats else \"cats\"\n",
        "proba = dogs if dogs > cats else cats\n",
        "label = \"{}: {:.2f}%\".format(label, proba * 100)\n",
        "# draw the label on the image\n",
        "output = imutils.resize(orig, width=400)\n",
        "cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n",
        "    0.7, (0, 255, 0), 2)\n",
        "# show the output image\n",
        "cv2_imshow(output)\n",
        "cv2.waitKey(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grad-Cam Method"
      ],
      "metadata": {
        "id": "1h3leflLHb3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZeBxhGdI1cq"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "class GradCAM:\n",
        "    def __init__(self, model, classIdx, layerName=None):\n",
        "        # store the model, the class index used to measure the class\n",
        "        # activation map, and the layer to be used when visualizing\n",
        "        # the class activation map\n",
        "        self.model = model\n",
        "        self.classIdx = classIdx\n",
        "        self.layerName = layerName\n",
        "        # if the layer name is None, attempt to automatically find\n",
        "        # the target output layer\n",
        "        if self.layerName is None:\n",
        "            self.layerName = self.find_target_layer()\n",
        "    def find_target_layer(self):\n",
        "            # attempt to find the final convolutional layer in the network\n",
        "            # by looping over the layers of the network in reverse order\n",
        "            for layer in reversed(self.model.layers):\n",
        "                # check to see if the layer has a 4D output\n",
        "                if len(layer.output_shape) == 4:\n",
        "                    return layer.name\n",
        "            # otherwise, we could not find a 4D layer so the GradCAM\n",
        "            # algorithm cannot be applied\n",
        "            raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
        "    def compute_heatmap(self, image, eps=1e-8):\n",
        "        # construct our gradient model by supplying (1) the inputs\n",
        "        # to our pre-trained model, (2) the output of the (presumably)\n",
        "        # final 4D layer in the network, and (3) the output of the\n",
        "        # softmax activations from the model\n",
        "        gradModel = Model(\n",
        "            inputs=[self.model.inputs],\n",
        "            outputs=[self.model.get_layer(self.layerName).output,\n",
        "                self.model.output])\n",
        "    # record operations for automatic differentiation\n",
        "        with tf.GradientTape() as tape:\n",
        "            # cast the image tensor to a float-32 data type, pass the\n",
        "            # image through the gradient model, and grab the loss\n",
        "            # associated with the specific class index\n",
        "            inputs = tf.cast(image, tf.float32)\n",
        "            (convOutputs, predictions) = gradModel(inputs)\n",
        "            loss = predictions[:, self.classIdx]\n",
        "        # use automatic differentiation to compute the gradients\n",
        "        grads = tape.gradient(loss, convOutputs)\n",
        "        # compute the guided gradients\n",
        "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
        "        castGrads = tf.cast(grads > 0, \"float32\")\n",
        "        guidedGrads = castConvOutputs * castGrads * grads\n",
        "        # the convolution and guided gradients have a batch dimension\n",
        "        # (which we don't need) so let's grab the volume itself and\n",
        "        # discard the batch\n",
        "        convOutputs = convOutputs[0]\n",
        "        guidedGrads = guidedGrads[0]\n",
        "        # compute the average of the gradient values, and using them\n",
        "        # as weights, compute the ponderation of the filters with\n",
        "        # respect to the weights\n",
        "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
        "        # grab the spatial dimensions of the input image and resize\n",
        "        # the output class activation map to match the input image\n",
        "        # dimensions\n",
        "        (w, h) = (image.shape[2], image.shape[1])\n",
        "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "        # normalize the heatmap such that all values lie in the range\n",
        "        # [0, 1], scale the resulting values to the range [0, 255],\n",
        "        # and then convert to an unsigned 8-bit integer\n",
        "        numer = heatmap - np.min(heatmap)\n",
        "        denom = (heatmap.max() - heatmap.min()) + eps\n",
        "        heatmap = numer / denom\n",
        "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
        "        # return the resulting heatmap to the calling function\n",
        "        return heatmap\n",
        "    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
        "        colormap=cv2.COLORMAP_VIRIDIS):\n",
        "        # apply the supplied color map to the heatmap and then\n",
        "        # overlay the heatmap on the input image\n",
        "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
        "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
        "        # return a 2-tuple of the color mapped heatmap and the output,\n",
        "        # overlaid image\n",
        "        return (heatmap, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test images with Grad-Cam Method"
      ],
      "metadata": {
        "id": "er_6wVGSHhGt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnOmM5kC3NHA"
      },
      "outputs": [],
      "source": [
        "model= load_model(\"/content/cats_and_dogs.h5\")\n",
        "image=\"/content/111.jpg\"\n",
        "# load the original image from disk and then\n",
        "# resize the image to its target dimensions\n",
        "image = cv2.imread(image)\n",
        "image = cv2.resize(image, (128, 128))\n",
        "orig=image.copy()\n",
        "# load the input image from disk (in Keras/TensorFlow format) and\n",
        "# preprocess it\n",
        "image = image.astype('float32')/255\n",
        "image = np.expand_dims(image, axis=0)\n",
        "# use the network to make predictions on the input image and find\n",
        "# the class label index with the largest corresponding probability\n",
        "preds = model.predict(image)\n",
        "i = np.argmax(preds[0])\n",
        "for idx in range(len(model.layers)):\n",
        "  print(model.get_layer(index = idx).name)\n",
        "# initialize our gradient class activation map and build the heatmap\n",
        "cam = GradCAM(model, i, 'conv2d_9')\n",
        "#print(cam)\n",
        "heatmap = cam.compute_heatmap(image)\n",
        "# resize the resulting heatmap to the original input image dimensions\n",
        "# and then overlay heatmap on top of the image\n",
        "heatmap = cv2.resize(heatmap, (128, 128))\n",
        "(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n",
        "fig, ax = plt.subplots(1, 3)\n",
        "ax[0].imshow(heatmap)\n",
        "ax[1].imshow(orig)\n",
        "ax[2].imshow(output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ddWiVNJ2l9Q"
      },
      "outputs": [],
      "source": [
        "plt.close('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5XlWEFzFuq4"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}